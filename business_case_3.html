<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Business Case 3: Live Event Network Traffic Management</title>
  <style>
    :root {
      --color-bg: #f4f4f7;
      --color-text: #1c1f26;
      --color-accent: #0d47a1;
      --color-highlight: #ffffff;
      --color-muted: #607d8b;
      --color-shadow: rgba(0, 0, 0, 0.06);
      --primary-shade: #0a2e6e;
      --border-radius: 10px;
      --section-bg: #e9edf2;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
      font-family: 'Montserrat', sans-serif;
    }

    body {
      background: linear-gradient(-45deg, #e9edf2, #f4f4f7, #dce3ea, #eef1f4);
      background-size: 400% 400%;
      animation: gradientFlow 15s ease infinite;
      color: var(--color-text);
      line-height: 1.8;
      padding: 2rem;
    }

    .container {
      max-width: 1200px;
      margin: auto;
      padding: 2rem;
      background: rgba(255, 255, 255, 0.75);
      backdrop-filter: blur(6px);
      border-radius: var(--border-radius);
      box-shadow: 0 6px 20px var(--color-shadow);
    }

    h1 {
      font-size: 2.5rem;
      color: var(--color-accent);
      text-align: center;
      margin-bottom: 2rem;
      border-bottom: 2px solid #ddd;
      padding-bottom: 0.8rem;
    }

    h2 {
      font-size: 1.8rem;
      color: var(--primary-shade);
      margin: 2rem 0 1rem;
    }

    h3 {
      font-size: 1.4rem;
      color: var(--color-text);
      margin: 1.5rem 0 1rem;
    }

    p {
      font-size: 1.1rem;
      margin-bottom: 1.5rem;
    }

    ul {
      list-style-type: disc;
      padding-left: 2rem;
      margin-bottom: 1.5rem;
    }

    li {
      font-size: 1.1rem;
      margin-bottom: 0.8rem;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 1.5rem 0;
    }

    th, td {
      padding: 1rem;
      border: 1px solid #ddd;
      text-align: left;
      font-size: 1.1rem;
    }

    th {
      background-color: var(--color-accent);
      color: white;
    }

    td {
      background-color: #f9f9f9;
    }

    pre {
      background: #f8f8f8;
      padding: 12px;
      border-left: 4px solid var(--color-accent);
      overflow-x: auto;
      font-size: 1rem;
      border-radius: var(--border-radius);
      margin: 1.5rem 0;
    }

    @keyframes gradientFlow {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }
  </style>
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
  <div class="container">
    <h1>Live Event Network Traffic Management</h1>
<img src="https://github.com/jiyapalrecha35/Google.github.io/blob/main/images/ford.gif?raw=true" alt="network traffic management" style="display: block; margin: 0 auto; width: 700px; height: 500px;">    
<p>
      This business case focuses on optimizing network traffic during large-scale live events, such as streamed concerts, sports broadcasts, or e-commerce flash sales, to minimize latency, ensure reliability, and enhance user experience. The approach leverages real-time traffic data, server capacities, and dynamic rerouting to manage data flows, prioritize critical requests, and adapt to changing network conditions.
    </p>
    <h2>Theory</h2>
    <p>
      Live Event Network Traffic Management involves coordinating data flows in a network of edge servers and origin points to prevent congestion and ensure seamless delivery. The network is modeled as a directed graph, where nodes represent servers (edge or origin) and edges represent connections with capacity constraints (e.g., bandwidth in Mbps). Real-time data from traffic monitors, user requests, and server health informs dynamic routing decisions, maximizing throughput while respecting capacity limits. Algorithms like Ford-Fulkerson optimize flow by finding paths with available bandwidth. Prioritizing critical requests (e.g., video streams, payment transactions) requires reserving bandwidth or computing dedicated routes. Key considerations include adapting to sudden spikes (e.g., millions of concurrent viewers), ensuring scalability for massive traffic, and maintaining reliability by avoiding bottlenecks and packet loss. Effective network management reduces latency, enhances quality of service, and improves the online event experience.
    </p>
    <h2>Real-Time Scenario</h2>
    <p>
      During a global live stream of a World Cup final, millions of users request video content from Akamai’s edge servers, straining bandwidth across regions. The network traffic management system models the network as a graph, with edge servers and origin servers as nodes and connections as edges, each assigned a bandwidth limit (Mbps). Real-time data from traffic monitors and user requests feeds into the system, which computes optimal data flows, routing traffic to underutilized edge servers to prevent congestion. For instance, as demand spikes in Europe, the system reroutes excess traffic to nearby servers with spare capacity, ensuring smooth streaming. Critical requests, like live video packets, are prioritized with reserved bandwidth or faster routes, maintaining quality. When a server outage occurs, the system instantly recomputes flows, redirecting traffic to alternative nodes to avoid disruptions. Bandwidth is allocated efficiently based on real-time server health, and traffic surges are managed dynamically, ensuring a reliable, low-latency experience for all viewers.
    </p>
    <h2>Usage</h2>
    <p>
      For Akamai, Live Event Network Traffic Management optimizes digital traffic during high-demand online events, ensuring seamless delivery and supporting client success. Key use cases include:
    </p>
    <ul>
      <li><strong>Live Streaming Optimization</strong>: Managing millions of concurrent viewers by routing requests to underutilized edge servers, ensuring low-latency streaming.</li>
      <li><strong>Peak Traffic Handling</strong>: Balancing network load during flash sales or live broadcasts, maintaining performance and uptime.</li>
      <li><strong>Priority Data Flows</strong>: Prioritizing critical data (e.g., video streams, payment transactions) with reserved bandwidth for reliable delivery.</li>
      <li><strong>Dynamic Surge Management</strong>: Adjusting traffic flows in real-time to handle sudden spikes, preventing bottlenecks and packet loss.</li>
      <li><strong>Real-Time Analytics</strong>: Providing insights on traffic patterns to optimize future event planning and server allocation.</li>
    </ul>

    <h2>Impact</h2>
    <p>
      Implementing Live Event Network Traffic Management provides significant benefits for Akamai’s clients and operations:
    </p>
    <ul>
      <li><strong>Reduced Latency</strong>: Optimizing traffic flows cuts delivery times by 30-50%, improving user satisfaction for live streams.</li>
      <li><strong>Enhanced Reliability</strong>: Ensuring 99.99% uptime and stable streaming boosts viewer engagement by 20-30%.</li>
      <li><strong>Improved Quality</strong>: Prioritizing critical data reduces packet loss by 40%, enhancing video and transaction quality.</li>
      <li><strong>Cost Efficiency</strong>: Minimizing server overload and optimizing bandwidth reduces operational costs by 15-25%.</li>
      <li><strong>Market Differentiation</strong>: Offering robust network traffic management strengthens Akamai’s position as a leader in live event solutions.</li>
    </ul>
    <h2>Challenges</h2>
    <ul>
      <li>Dynamic conditions: Real-time changes in traffic, server outages, or demand spikes require rapid adaptation.</li>
      <li>Capacity constraints: Bandwidth and server resources have limits, risking congestion.</li>
      <li>Priority handling: Ensuring low latency for critical data like video streams or transactions.</li>
      <li>Scalability: Managing millions of requests across a global network.</li>
      <li>Reliability: Minimizing packet loss and downtime in high-traffic scenarios.</li>
    </ul>

    <h2>Algorithms Used</h2>
    <p>Below are the algorithms evaluated for live event network traffic management, with summaries of their purpose and detailed explanations of their mechanics, followed by simplified implementations:</p>

    <h2>Ford-Fulkerson</h2>
    <p>
      This algorithm maximizes data throughput in a network by finding the optimal flow of traffic from users to edge servers and origin points, respecting bandwidth limits, using a breadth-first search approach[11].
    </p>
    <h3>How It Works</h3>
    <p>
      This algorithm, using the Edmonds-Karp variant, maximizes network traffic flow through a graph, where nodes are servers (edge or origin) and edges are connections with bandwidth limits (Mbps). It employs Breadth-First Search (BFS) to find augmenting paths—routes from the source (users) to the sink (content delivery point) with available bandwidth. For each path, the algorithm sends the maximum possible flow (limited by the smallest bandwidth along the path), updating residual capacities to reflect the flow used. This process repeats until no augmenting paths remain, ensuring maximum data delivery without exceeding bandwidth limits. In practice, this means rerouting traffic to less congested servers during a live stream, such as directing requests to regional edge servers when primary ones are saturated. The algorithm also supports prioritizing critical data by reserving bandwidth on specific edges, ensuring faster delivery.
    </p>
    <pre>
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#define MAX_NODES 100
#define INF 1000000

typedef struct {
    int from, to;
    int capacity;
} Edge;

int bfs(int** residual, int* parent, int source, int sink, int numNodes) {
    memset(parent, -1, numNodes * sizeof(int));
    int visited[MAX_NODES] = {0};
    int queue[MAX_NODES], front = 0, rear = 0;
    queue[rear++] = source;
    visited[source] = 1;
    
    while (front < rear) {
        int u = queue[front++];
        for (int v = 0; v < numNodes; v++) {
            if (!visited[v] && residual[u][v] > 0) {
                parent[v] = u;
                visited[v] = 1;
                queue[rear++] = v;
                if (v == sink) return 1;
            }
        }
    }
    return 0;
}

int fordFulkerson(int** graph, int source, int sink, int numNodes) {
    int** residual = (int**)malloc(numNodes * sizeof(int*));
    for (int i = 0; i < numNodes; i++) {
        residual[i] = (int*)malloc(numNodes * sizeof(int));
        for (int j = 0; j < numNodes; j++) residual[i][j] = graph[i][j];
    }
    
    int parent[MAX_NODES], maxFlow = 0;
    
    while (bfs(residual, parent, source, sink, numNodes)) {
        int pathFlow = INF;
        for (int v = sink; v != source; v = parent[v]) {
            int u = parent[v];
            pathFlow = pathFlow < residual[u][v] ? pathFlow : residual[u][v];
        }
        
        for (int v = sink; v != source; v = parent[v]) {
            int u = parent[v];
            residual[u][v] -= pathFlow;
            residual[v][u] += pathFlow;
        }
        maxFlow += pathFlow;
    }
    
    for (int i = 0; i < numNodes; i++) free(residual[i]);
    free(residual);
    return maxFlow;
}

int main() {
    int numNodes = 7;
    int** graph = (int**)malloc(numNodes * sizeof(int*));
    for (int i = 0; i < numNodes; i++) {
        graph[i] = (int*)calloc(numNodes, sizeof(int));
    }
    
    // Graph: Source (0, users), Edge Servers (1-5), Sink (6, content delivery)
    graph[0][1] = 500; graph[0][2] = 400; graph[1][3] = 300; graph[2][3] = 200;
    graph[2][4] = 250; graph[3][5] = 350; graph[4][5] = 150; graph[5][6] = 450;
    
    printf("Ford-Fulkerson (Edmonds-Karp) Simulation:\n");
    int maxFlow = fordFulkerson(graph, 0, 6, numNodes);
    printf("Maximum network traffic flow: %d Mbps\n", maxFlow);
    
    for (int i = 0; i < numNodes; i++) free(graph[i]);
    free(graph);
    return 0;
}
    </pre>

    <h2>Min-Cut Max-Flow</h2>
    <p>
      This algorithm extends Ford-Fulkerson to maximize network traffic flow and identify critical bandwidth bottlenecks that limit data throughput, aiding in congestion mitigation planning.
    </p>
    <h3>How It Works</h3>
    <p>
      Building on Ford-Fulkerson (Edmonds-Karp), this algorithm not only computes the maximum flow but also identifies the minimum cut—the smallest set of connections (edges) that, if saturated, would prevent additional data from reaching the delivery point. After calculating the maximum flow using BFS to find augmenting paths, a final BFS on the residual graph marks nodes reachable from the source. Edges connecting these reachable nodes to unreachable ones form the min-cut, highlighting critical bottlenecks, such as overused server connections or limited bandwidth links. In a real-world scenario, this helps planners identify which network paths need capacity upgrades or load balancing to prevent congestion during a live stream. For example, during a global broadcast, it might reveal that a key link to an edge server is the limiting factor, prompting traffic rerouting or server scaling.
    </p>
    <pre>
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#define MAX_NODES 100
#define INF 1000000

typedef struct {
    int from, to;
    int capacity;
} Edge;

int bfs(int** residual, int* visited, int source, int numNodes) {
    memset(visited, 0, numNodes * sizeof(int));
    int queue[MAX_NODES], front = 0, rear = 0;
    queue[rear++] = source;
    visited[source] = 1;
    
    while (front < rear) {
        int u = queue[front++];
        for (int v = 0; v < numNodes; v++) {
            if (!visited[v] && residual[u][v] > 0) {
                queue[rear++] = v;
                visited[v] = 1;
            }
        }
    }
    return visited[source];
}

int minCutMaxFlow(int** graph, int source, int sink, int numNodes, Edge* cutEdges, int* cutSize) {
    int** residual = (int**)malloc(numNodes * sizeof(int*));
    for (int i = 0; i < numNodes; i++) {
        residual[i] = (int*)malloc(numNodes * sizeof(int));
        for (int j = 0; j < numNodes; j++) residual[i][j] = graph[i][j];
    }
    
    int parent[MAX_NODES], maxFlow = 0;
    while (bfs(residual, parent, source, numNodes)) {
        int pathFlow = INF;
        for (int v = sink; v != source; v = parent[v]) {
            int u = parent[v];
            pathFlow = pathFlow < residual[u][v] ? pathFlow : residual[u][v];
        }
        for (int v = sink; v != source; v = parent[v]) {
            int u = parent[v];
            residual[u][v] -= pathFlow;
            residual[v][u] += pathFlow;
        }
        maxFlow += pathFlow;
    }
    
    int visited[MAX_NODES];
    bfs(residual, visited, source, numNodes);
    
    *cutSize = 0;
    for (int u = 0; u < numNodes; u++) {
        if (visited[u]) {
            for (int v = 0; v < numNodes; v++) {
                if (!visited[v] && graph[u][v] > 0) {
                    cutEdges[*cutSize].from = u;
                    cutEdges[*cutSize].to = v;
                    cutEdges[*cutSize].capacity = graph[u][v];
                    (*cutSize)++;
                }
            }
        }
    }
    
    for (int i = 0; i < numNodes; i++) free(residual[i]);
    free(residual);
    return maxFlow;
}

int main() {
    int numNodes = 7;
    int** graph = (int**)malloc(numNodes * sizeof(int*));
    for (int i = 0; i < numNodes; i++) {
        graph[i] = (int*)calloc(numNodes, sizeof(int));
    }
    
    // Graph: Source (0, users), Edge Servers (1-5), Sink (6, content delivery)
    graph[0][1] = 500; graph[0][2] = 400; graph[1][3] = 300; graph[2][3] = 200;
    graph[2][4] = 250; graph[3][5] = 350; graph[4][5] = 150; graph[5][6] = 450;
    
    Edge cutEdges[MAX_NODES * MAX_NODES];
    int cutSize;
    
    printf("Min-Cut Max-Flow Simulation:\n");
    int maxFlow = minCutMaxFlow(graph, 0, 6, numNodes, cutEdges, &cutSize);
    printf("Maximum network traffic flow: %d Mbps\n", maxFlow);
    printf("Min-Cut edges (bottlenecks):\n");
    for (int i = 0; i < cutSize; i++) {
        printf("Edge %d->%d (Bandwidth: %d Mbps)\n", cutEdges[i].from, cutEdges[i].to, cutEdges[i].capacity);
    }
    
    for (int i = 0; i < numNodes; i++) free(graph[i]);
    free(graph);
    return 0;
}
    </pre>

    <h2>Time and Space Complexity</h2>
    <table>
      <tr>
        <th>Algorithm</th>
        <th>Best Case Time</th>
        <th>Typical Case Time</th>
        <th>Worst Case Time</th>
        <th>Space Complexity</th>
      </tr>
      <tr>
        <td>Ford-Fulkerson (Edmonds-Karp)</td>
        <td>O(E)</td>
        <td>O(V * E^2)</td>
        <td>O(V * E^2)</td>
        <td>O(V + E)</td>
      </tr>
      <tr>
        <td>Min-Cut Max-Flow</td>
        <td>O(E)</td>
        <td>O(V * E^2)</td>
        <td>O(V * E^2)</td>
        <td>O(V + E)</td>
      </tr>
    </table>
    <p>
      Note: V = number of vertices (servers), E = number of edges (connections). Ford-Fulkerson and Min-Cut Max-Flow have high worst-case complexity.
    </p>

    <h2>Inference</h2>
    <p>
      For Live Event Network Traffic Management, Ford-Fulkerson (Edmonds-Karp) is the recommended algorithm. It excels in optimizing dynamic data flow by maximizing throughput while respecting bandwidth constraints, making it ideal for real-time rerouting to avoid bottlenecks during events like live streams or flash sales. Min-Cut Max-Flow is a close second, offering similar flow optimization with the added benefit of identifying critical network bottlenecks for predictive control. Ford-Fulkerson’s ability to handle live capacity constraints ensures efficient, reliable traffic management for large-scale online events.
    </p>
  </div>
</body>
</html>
